{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn-extra"
      ],
      "metadata": {
        "id": "Nh0R952vAYpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L6mJ5GWbRB3I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from numba import jit\n",
        "from numba import njit\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g4yc611kRzyT"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def minkowskiDistance(a, b, p):\n",
        "    return np.sum(np.abs(a - b) ** p) ** (1 / p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pEBQNTA1XJ_R"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def distanceMatrix(points, p):\n",
        "  # Recebe um array de pontos com os rótulos removidos e retorna a matriz de distâncias entre eles\n",
        "  size = points.shape[0]\n",
        "  distance = np.zeros((size, size))\n",
        "  for i in range(size):\n",
        "    for j in range(size):\n",
        "      distance[i, j] = minkowskiDistance(points[i], points[j], p)\n",
        "  return distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SJUvaPwvT8tI"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def KMeans1Aux(points, distance_matrix, r):\n",
        "    num_points = len(points)\n",
        "    centers = np.empty((num_points, points.shape[1]))\n",
        "    centersIdx = np.empty(num_points, dtype=np.int64)\n",
        "    remaining_points = np.ones(num_points, dtype=np.bool_)\n",
        "    count = 0\n",
        "\n",
        "    while np.any(remaining_points):\n",
        "        center_idx = np.random.choice(np.where(remaining_points)[0])\n",
        "        centers[count] = points[center_idx]\n",
        "        centersIdx[count] = center_idx\n",
        "        distances = distance_matrix[center_idx, remaining_points]\n",
        "        remaining_points[remaining_points] = distances >= r\n",
        "        count+=1\n",
        "    return centers[:count] #retorno somentes dos centros que foram instanciados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GLEaq127ZP7Q"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def KMeans1(k, points, distance_matrix):\n",
        "  # Implementação do KMeans por aproximação baseada na convergência\n",
        "  rmax = np.max(distance_matrix)\n",
        "  low = 0\n",
        "  high = rmax\n",
        "  centers = np.empty((k, points.shape[1]))\n",
        "\n",
        "  while high - low > 0.000001:\n",
        "    mid = (high + low) / 2\n",
        "    centers = KMeans1Aux(points, distance_matrix, mid)\n",
        "    if len(centers) <= k:\n",
        "      high = mid\n",
        "    else:\n",
        "      low = mid\n",
        "\n",
        "  return centers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D7PHs6rvdp3S"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def KMeans2(k, points, distance_matrix):\n",
        "    # Implementação do KMeans por aproximação gulosa\n",
        "    num_points = len(points)\n",
        "    centers_idx = np.array([np.random.choice(num_points)])\n",
        "    centers = [points[centers_idx[0]]]\n",
        "\n",
        "    while len(centers) < k:\n",
        "        min_dists = np.full(num_points, np.inf)\n",
        "        for i in range(num_points):\n",
        "            for j in range(len(centers_idx)):\n",
        "                if distance_matrix[i, centers_idx[j]] < min_dists[i]:\n",
        "                    min_dists[i] = distance_matrix[i, centers_idx[j]]\n",
        "\n",
        "        max_idx = np.argmax(min_dists)\n",
        "        max_point = points[max_idx]\n",
        "\n",
        "        centers_idx = np.append(centers_idx, max_idx)\n",
        "        centers.append(max_point)\n",
        "\n",
        "    return centers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YCM6kT8Oc-1e"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def get_k_size(file_name):\n",
        "  # Lê o número de clusters com base no nome do arquivo\n",
        "  return file_name.split('_')[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cUOehZ1AjUcR"
      },
      "outputs": [],
      "source": [
        "def get_points_and_distance_matrix(data, p):\n",
        "  points = data.iloc[:, :-1].values\n",
        "  dist = distanceMatrix(points, p)\n",
        "  return points, dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NeshsMmrj_Tw"
      },
      "outputs": [],
      "source": [
        "def get_data_from_k_mean_1(k_size, points, dist, metric, labels_true):\n",
        "  centers = KMeans1(k_size, points, dist)\n",
        "  distances = pairwise_distances_argmin_min(points, centers,metric=metric)[1]\n",
        "  labels_pred = pairwise_distances_argmin(points, centers,metric=metric)\n",
        "  silhouette = silhouette_score(points, labels_pred) if len(np.unique(labels_pred)) > 1 else 0\n",
        "  adjusted_rand = adjusted_rand_score(labels_true, labels_pred)\n",
        "  return  np.max(distances), silhouette, adjusted_rand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hAGbzGC8cTd5"
      },
      "outputs": [],
      "source": [
        "def get_data_from_k_mean_2(k_size, points, dist,metric, labels_true):\n",
        "  centers = KMeans2(k_size, points, dist)\n",
        "  distances = pairwise_distances_argmin_min(points, centers,metric=metric)[1]\n",
        "  labels_pred = pairwise_distances_argmin(points, centers,metric=metric)\n",
        "  silhouette = silhouette_score(points, labels_pred) if len(np.unique(labels_pred)) > 1 else 0\n",
        "  adjusted_rand = adjusted_rand_score(labels_true, labels_pred)\n",
        "  return  np.max(distances), silhouette, adjusted_rand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h9N70CXfkA7S"
      },
      "outputs": [],
      "source": [
        "def get_data_from_kmeans(k_size, points, dist, data,metric):\n",
        "    # Define o tipo de métrica e o modelo de clustering baseado no tipo de métrica (manhattam ou euclidian)\n",
        "    if metric == 'manhattan':\n",
        "        clustering_model = KMedoids(n_clusters=k_size, metric=metric, random_state=0)\n",
        "    else:\n",
        "        clustering_model = KMeans(n_clusters=k_size, random_state=0, n_init='auto')\n",
        "\n",
        "    # Executa o ajuste do modelo aos pontos\n",
        "    clustering_model.fit(points)\n",
        "    labels_pred = clustering_model.labels_\n",
        "    centers = clustering_model.cluster_centers_\n",
        "\n",
        "    # Calcula a distância máxima dos pontos ao centroide mais próximo\n",
        "    distances = pairwise_distances_argmin_min(points, centers, metric=metric)[1]\n",
        "    max_distance = np.max(distances)\n",
        "\n",
        "    # Calcula o silhouette score e o adjusted rand index\n",
        "    labels_true = data.iloc[:, -1].values\n",
        "    # Caso todos os labels sejam do msm centro, silhoutte será 0\n",
        "    silhouette = silhouette_score(points, labels_pred) if len(np.unique(labels_pred)) > 1 else 0\n",
        "    adjusted_rand = adjusted_rand_score(labels_true, labels_pred)\n",
        "\n",
        "    return max_distance, silhouette, adjusted_rand\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vbgd_Uc-AVbJ"
      },
      "outputs": [],
      "source": [
        "def max_distance_for_same_label(matrix, matrix_distances, p):\n",
        "# Calcula a distância máxima entre pontos com o mesmo label para os rótulos originais\n",
        "    max_distance = 0\n",
        "\n",
        "    labels = np.unique(matrix[:, -1])\n",
        "\n",
        "    for label in labels:\n",
        "        points = matrix[matrix[:, -1] == label][:, :-1].astype(np.float64)\n",
        "        matrix_distances = distanceMatrix(points, p)\n",
        "\n",
        "        for i in range(len(points)):\n",
        "            for j in range(i + 1, len(points)):\n",
        "                dist = matrix_distances[i, j]\n",
        "                if dist > max_distance:\n",
        "                    max_distance = dist\n",
        "\n",
        "    return  max_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b2B5RyUfcFSs"
      },
      "outputs": [],
      "source": [
        "def get_information(directory_path, output_csv):\n",
        "    if not os.path.isdir(directory_path):\n",
        "        print(f\"O caminho {directory_path} não é uma pasta válida.\")\n",
        "        return\n",
        "\n",
        "    # Lista para armazenar os resultados\n",
        "    results = []\n",
        "    metric = ['manhattan', 'euclidean']\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        file_path = os.path.join(directory_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            data = pd.read_csv(file_path, header=None)\n",
        "            print(file_name)\n",
        "            k_center = int(get_k_size(file_name))\n",
        "            labels_true = data.iloc[:, -1].values\n",
        "            for p in [1,2]:\n",
        "              points, dist = get_points_and_distance_matrix(data, p)\n",
        "              estimated_distance = max_distance_for_same_label(data.values, dist, p)\n",
        "              for i in range(30):\n",
        "                  # Roda a instância para o primeiro método k_mean_1\n",
        "                  start_time = time.time()\n",
        "                  max_distance_k_mean_1, silhouette_1,adjusted_rand_1 = get_data_from_k_mean_1(k_center, points, dist, metric[p -1], labels_true)\n",
        "                  elapsed_time_1 = time.time() - start_time\n",
        "\n",
        "                  # Roda a instância para o primeiro método k_mean_2\n",
        "                  start_time = time.time()\n",
        "                  max_distance_k_mean_2, silhouette_2,adjusted_rand_2 = get_data_from_k_mean_2(k_center, points, dist, metric[p -1], labels_true)\n",
        "                  elapsed_time_2 = time.time() - start_time\n",
        "\n",
        "                  # Roda instância para o k-Means implementeado no sklearn\n",
        "                  start_time = time.time()\n",
        "                  max_distance_k_means, silhouette_3, adjusted_rand_3 = get_data_from_kmeans(k_center, points, dist, data, metric[p -1])\n",
        "                  elapsed_time_3 = time.time() - start_time\n",
        "\n",
        "                  results.append({\n",
        "                      'instance': file_name,\n",
        "                      'centers_number': k_center,\n",
        "                      'size': data.shape[0],\n",
        "                      'p': p,\n",
        "                      'iteration': i + 1,\n",
        "                      'max_distance_k_mean_1': max_distance_k_mean_1,\n",
        "                      'silhouette_k_mean_1': silhouette_1,\n",
        "                      'adjusted_rand_k_mean_1': adjusted_rand_1,\n",
        "                      'execution_time_k_mean_1': elapsed_time_1,\n",
        "                      'max_distance_k_mean_2': max_distance_k_mean_2,\n",
        "                      'silhouette_k_mean_2': silhouette_2,\n",
        "                      'adjusted_rand_k_mean_2': adjusted_rand_2,\n",
        "                      'execution_time_k_mean_2': elapsed_time_2,\n",
        "                      'max_distance_k_means_skt': max_distance_k_means,\n",
        "                      'execution_time_k_means_skt': elapsed_time_3,\n",
        "                      'silhouette_k_means_skt': silhouette_3,\n",
        "                      'adjusted_rand_k_means_skt': adjusted_rand_3,\n",
        "                      'estimated': estimated_distance\n",
        "\n",
        "                  })\n",
        "\n",
        "    # Criar um DataFrame a partir dos resultados e salvar em CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(output_csv, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixlIqigmEQpw"
      },
      "outputs": [],
      "source": [
        "get_information('/content/real_data', 'output_results.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}